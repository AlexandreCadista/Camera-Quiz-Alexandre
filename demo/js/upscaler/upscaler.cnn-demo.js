(self.webpackChunkUpscaler=self.webpackChunkUpscaler||[]).push([[79],{592:(e,t,n)=>{"use strict";n.r(t),n.d(t,{default:()=>m});var o=n(891),i=n(795),r=n(870),s=n(9);class u extends s.Z{constructor(e,t,n){super(e,t,n=n)}formatWeights(e){const t=e.weights,n=e.biases,o=[],i=[0,1,2,0,1,2,0,1,2],r=[0,0,0,1,1,1,2,2,2];for(let e=0;e<9;e++){const n=i[e],s=r[e];for(let e=0;e<t.length;e++)o.push(t[e][0][s][n])}return{weights:o,biases:n}}fragmentShader(){const e=this.gl;return e.createAndCompileShader(e.FRAGMENT_SHADER,"#version 300 es \n            // Use high precision floats\n            precision highp float;\n            \n            // The output feature texture\n            layout(location = 0) out vec4 outputFeatures;\n\n            /* If one has 8 output features we use more layout locations\n            layout(location = 1) out vec4 outputFeatures2;\n            */\n\n            // Input YUV image\n            uniform sampler2D u_image;\n\n            // Size of the image saved in a vec2 array\n            uniform vec2 u_textureSize;\n\n            // channel feature weights\n            uniform vec4 u_kernel[9];\n\n            // channel bias\n            uniform vec4 u_bias[1];\n\n            // The offsets that should be added to the position of the image to \n            // get the neighbors of the current pixel position.\n            uniform vec2 kernel_offset[9];\n\n            // Current position of the pixel in the texture space\n            in vec2 v_texCoord;\n              \n            // Helper function to perform relu\n            vec4 relu(vec4 color){\n            return vec4(max(0.0, color.r),\n                        max(0.0, color.g),\n                        max(0.0, color.b),\n                        max(0.0, color.a));\n            }\n              \n            // this main() function is called every time we are convolving/shading a pixel\n            void main() {\n                /*\n                Get the per pixel position size in [0, 1] space\n                So if the the size of the image is 10x10 then \n                per pixel size for [0, 1] span is (1, 1)/(10, 10) -> (0.1, 0.1).\n                This scaling factor can be used to scale the neighboring offset \n                from [0, 0, w, h] space into [0, 0, 1, 1] space.\n                For eg., the top right pixel position w.r.t current pixel position\n                can be accessed using \n                scale*(curr_pix.x, curr_pix.y)\n                */\n\n                vec2 onePixel = vec2(1.0, 1.0) / (u_textureSize);\n\n                //Iterate through each weight index\n                for (int i =0; i < 9; i++){\n                    // Get neighboring/current yChannel value based on the kernel_offset.\n                    // kernel_offset looks something like this,\n                    // [(-1,-1), (0, -1), (1, -1), (-1, 0), (0, 0), (1, 0), (-1, 1), (0, 1), (1, 1)]\n                    float yChannel = texture(u_image, v_texCoord + (onePixel * kernel_offset[i]) )[0];\n\n                    outputFeatures += yChannel * u_kernel[i];\n                }\n\n                // Add bias to the output\n                outputFeatures += u_bias[0];\n                // Perform relu\n                outputFeatures = relu(outputFeatures);\n            }\n    ")}uniforms(){return["u_resolution","u_textureSize","u_image","u_kernel","u_bias","kernel_offset","u_flipY"]}setTextureBufferForLayer(e){e.createBufferWithTextures("Conv1",1)}setOutput(e){e.setBuffer("Conv1");const t=this.gl;t.drawBuffers([t.COLOR_ATTACHMENT0])}setInput(e){const t=this.gl;t.uniform1i(this.locations.u_image,0),t.activeTexture(t.TEXTURE0),t.bindTexture(t.TEXTURE_2D,e.getTexture("YUV")[0])}setFragmentPointers(){const e=this.gl,t=this.locations;let n=new Float32Array(this.weights.weights),o=new Float32Array(this.weights.biases);const i=new Float32Array([-1,-1,0,-1,1,-1,-1,0,0,0,1,0,-1,1,0,1,1,1]);e.uniform2fv(t.kernel_offset,i),e.uniform2f(t.u_textureSize,e.input.w,e.input.h),e.uniform4fv(t.u_kernel,n),e.uniform4fv(t.u_bias,o)}}const a=u;class l extends s.Z{constructor(e,t,n){super(e,t,n=n)}formatWeights(e){const t=e.weights,n=e.biases,o=[],i=[0,1,2,0,1,2,0,1,2],r=[0,0,0,1,1,1,2,2,2];for(let e=0;e<9;e++){const n=i[e],s=r[e];for(let e=0;e<4;e++)for(let i=0;i<4;i++)o.push(t[e][i][s][n])}return{weights:o,biases:n}}fragmentShader(){const e=this.gl;return e.createAndCompileShader(e.FRAGMENT_SHADER,"#version 300 es \n            // Use high precision floats\n            precision highp float;\n            \n            // Input features from previous layer\n            uniform sampler2D inputStack;\n            \n            // The output features texture\n            layout(location = 0) out vec4 outputFeatures;\n\n            // /* If one has 8 output features we use more layout locations\n            //     layout(location = 1) out vec4 outputFeatures2;\n            // */\n\n\n            // Size of the image saved in a vec2 array\n            uniform vec2 u_textureSize;\n\n            // channel feature weights\n            uniform mat4 kernelMat[9];\n  \n            // channel bias\n            uniform vec4 u_bias[1];\n  \n            // The offsets that should be added to the position \n            // of the image to get the neighbors of the current pixel position.\n            uniform vec2 kernel_offset[9];\n  \n            // Current position of the pixel in the texture space\n            in vec2 v_texCoord;\n            \n            // Helper function to perform relu\n            vec4 relu(vec4 color){\n              return vec4(max(0.0, color.r),\n                          max(0.0, color.g),\n                          max(0.0, color.b),\n                          max(0.0, color.a));\n            }\n            \n            // this main() function is called every time we are convolving/shading a pixel\n            void main() {\n                  // Get the per pixel position size in [0, 1] space\n                  // So if the the size of the image is 10x10 then \n                  // per pixel size for [0, 1] span is (1, 1)/(10, 10) -> (0.1, 0.1).\n                  // This scaling factor can be used to scale the neighboring offset \n                  // from [0, 0, w, h] space into [0, 0, 1, 1] space.\n                  // For eg., the top right pixel position w.r.t current pixel position\n                  // can be accessed using \n                  // scale*(curr_pix.x, curr_pix.y)\n                  vec2 onePixel = vec2(1.0, 1.0) / (u_textureSize);\n  \n                  //Iterate through each weight index\n                  for (int i =0; i < 9; i++){\n                      // Get neighbouring/current inputStack values based on the kernel_offset.\n                      // kernel_offset looks something like this,\n                      // [(-1,-1), (0, -1), (1, -1), (-1, 0), (0, 0), (1, 0), (-1, 1), (0, 1), (1, 1)]\n                      vec4 inputChannels = texture(inputStack, v_texCoord + (onePixel * kernel_offset[i])) ;\n                      outputFeatures += inputChannels * kernelMat[i];\n\n                    }\n\n                    // Add bias to the output\n                    outputFeatures += u_bias[0];\n\n                    //Perform relu\n                    outputFeatures = relu(outputFeatures);\n     \n              }\n        ")}uniforms(){return["u_resolution","u_textureSize","inputStack","kernelMat","u_bias","kernel_offset","u_flipY"]}setTextureBufferForLayer(e){e.createBufferWithTextures("Conv2",1)}setOutput(e){e.setBuffer("Conv2");const t=this.gl;t.drawBuffers([t.COLOR_ATTACHMENT0])}setInput(e){const t=this.gl;t.activeTexture(t.TEXTURE0+0),t.uniform1i(this.locations.inputStack,0),t.bindTexture(t.TEXTURE_2D,e.getTexture("Conv1")[0])}setFragmentPointers(){const e=this.gl,t=this.locations;let n=new Float32Array(this.weights.weights),o=new Float32Array(this.weights.biases);const i=new Float32Array([-1,-1,0,-1,1,-1,-1,0,0,0,1,0,-1,1,0,1,1,1]);e.uniform2fv(t.kernel_offset,i),e.uniform2f(t.u_textureSize,e.input.w,e.input.h),e.uniformMatrix4fv(t.kernelMat,!1,n),e.uniform4fv(t.u_bias,o)}}const c=l;var f=n(67);class h extends f.Z{constructor(e,t){super(e),this.layer_name=t}fragmentShader(){const e=this.gl;return e.createAndCompileShader(e.FRAGMENT_SHADER,"#version 300 es\n            precision mediump float;\n            // Input texture to perform superpixel on\n            uniform sampler2D inputStack;\n            // Low resolution YUV image\n            uniform sampler2D YUV;\n            \n            // Size of the upscaled image\n            uniform vec2 u_textureSize;\n            // Current pixel location\n            in vec2 v_texCoord;\n            // output pixel color of the upscaled image\n            out vec4 outColor;\n            \n            void main() {\n            \n                /*\n                Map the upscaled texture image co-ordinates to canvas co-ordinates\n                */\n                vec2 canvasCoords = v_texCoord*u_textureSize;\n                int i = int(canvasCoords[0]);\n                int j  = int(canvasCoords[1]);\n                \n                // Based on the condition we push the pixel value from one \n                // of the 4 input channels\n                if(i % 2 == 0 && j % 2 ==0){\n                    outColor[0] = texture(inputStack, v_texCoord)[0];\n                }\n                if(i % 2 == 1 && j % 2 ==0){\n                    outColor[0] = texture(inputStack, v_texCoord)[1];\n                }                \n                if(i % 2 == 0 && j % 2 ==1){\n                    outColor[0] = texture(inputStack, v_texCoord)[2];\n                }\n                if(i % 2 == 1 && j % 2 ==1){\n                    outColor[0] = texture(inputStack, v_texCoord)[3];\n                }\n\n                // Read the U and V channel output from the low resolution\n                // YUV image. The pixel value interpolation is taken care\n                // of webgl2 by itself\n                outColor[1] =  texture(YUV, v_texCoord)[1];\n                outColor[2] =  texture(YUV, v_texCoord)[2];\n                \n                // Make alpha channel equal to 1\n                outColor[3] = 1.0;\n                    \n            }\n        ")}setOutput(e){e.setBuffer("PixelShuffle");const t=this.gl;t.drawBuffers([t.COLOR_ATTACHMENT0])}setTextureBufferForLayer(e){e.createBufferWithTextures("PixelShuffle",1,2)}setInput(e){const t=this.gl;t.uniform1i(this.locations.inputStack,0),t.activeTexture(t.TEXTURE0),t.bindTexture(t.TEXTURE_2D,e.getTexture(this.layer_name)[0]),t.uniform1i(this.locations.YUV,1),t.activeTexture(t.TEXTURE1),t.bindTexture(t.TEXTURE_2D,e.getTexture("YUV")[0])}uniforms(){return["u_resolution","u_textureSize","YUV","inputStack","bias","kernel_offset","u_flipY"]}setFragmentPointers(){const e=this.gl,t=this.locations;e.uniform2f(t.u_textureSize,2*e.input.w,2*e.input.h),e.uniform1f(t.u_flipY,1)}}const p=h;class x extends o.Z{constructor(e,t,n){super(e,t,n)}async getImageBytes(){this.frameBuffer.iterations}model(){const e=this.gl;return e.resizeCanvasToDisplaySize(2),[new i.Z(e,{scale:2}),new a(e,this.Parameters.conv1,{scale:2,kernelSize:3,inChannels:1,outChannels:[0,4]}),new c(e,this.Parameters.conv2,{scale:2,kernelSize:3,inChannels:4,outChannels:[0,4]}),new p(e,"Conv2"),new r.Z(e)]}}const m=x}}]);